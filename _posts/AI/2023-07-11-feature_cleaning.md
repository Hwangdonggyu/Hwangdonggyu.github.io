---
title: AI Feature Cleaning 정리
date: 2023-07-11 20:25:00 +0900
categories: [AI]
tags: [AI]
---

![](https://velog.velcdn.com/images/acadias12/post/596daee7-7a2a-41b1-a038-da5f749d38a3/image.jpeg)

AI를 공부하면서 배운 Feature Cleaning에 대해 정리해보려 한다.


## Missing values (누락된 값)

> 정의 : 변수 내의 특정 값이 저장되어있지 않는 것

### 누락된 데이터가 중요한 이유
+ 누락된 값이 있는 경우 특정 알고리즘이 작동하지 않음
+ 누락된 데이터를 처리하지 않으면 모델이 정확하지 않은 결론을 내릴 수 있음.

### Missing Mechanisms (누락 메커니즘)

+ Missing Completely at Random (MCAR)
+ Missing at Random (MAR)
+ Missing Not At Random (MNAR)

#### 완전히 무작위로 누락된 변수 (MCAR)

>누락될 확률이 모든 관측치에 대해 동일한 경우 변수가 완전히 무작위로 누락된 것이다. 데이터가 MCAR인 경우 데이터 결측값과 데이터 집합 내의 다른 값(관측 또는 결측값) 사이에는 전혀 관계가 없다. 즉, 결측 데이터 점은 데이터의 랜덤 부분 집합이다. 관측치 값이 랜덤하게 완전히 누락된 경우 이러한 경우를 무시해도 추론이 편향되지 않는다.

#### 무작위 누락 (MAR)

> 결측값의 성향과 관측된 데이터 사이에 체계적인 관계가 있을 때 임의의 결측값(MAR)으로 결측값이 발생한다. 즉, 관측치가 누락될 확률은 사용 가능한 정보(데이터 세트의 다른 변수)에만 따라 달라지지만 변수 자체에는 따라 달라지지 않는다.

#### 무작위가 아닌 누락 (MNAR)
> 결측값이 무작위가 아닌 것이다. 관찰되지 않은 예측 변수에 따라 다르고, 누락된 값 자체에 따라 다르다.


### 누락된 데이터 처리 방법

|방법|정의|장점|단점|
|---|---|---|---|
|목록별 삭제|누락된 값이 있는 모든 사례(목록 방식) 제외|외	MCAR인 경우 배포 유지|1.너무 많은 데이터를 버리고 모델을 손상시킬 수 있음. <br>2.MCAR이 아닌 경우 편향된 추정치를 생성할 수 있음.| 
|평균/중앙값/모드 대치|NA를 해당 변수의 평균/중앙값/가장 빈번한 값(범주형 기능의 경우)으로 대체|MCAR의 경우 좋은 습관|1. 분포 왜곡 <br>    2. 다른 변수와의 관계 왜곡|
|배포 종료 귀속|	NA를 해당 변수 분포의 맨 끝에 있는 값으로 대체(mean + 3*std로 계산)|누락이 있는 경우 누락의 중요성을 포착함.|1. 왜곡 분포<br>2. NA가 적으면 이상값으로 간주되거나 NA가 많으면 실제 이상값을 마스킹할 수 있음.<br>3. 누락이 중요하지 않은 경우 원래 변수의 예측력을 가릴 수 있음.|
|무작위 전가|해당 변수의 사용 가능한 관찰 풀에서 임의의 값을 가져와 NA를 대체합니다.|MCAR인 경우 배포 유지|임의성으로 인해 비즈니스 설정에서는 권장되지 않음(동일한 입력에 대해 다른 결과)|
|임의 값 전가|NA를 임의의 값으로 대체|	누락이 있는 경우 누락의 중요성을 포착함.|1. 왜곡 분포<br>2. 일반적인 사용 값: -9999/9999. 그러나 이상값으로 간주될 수 있음.|
|NA를 나타내는 변수 추가|해당 관찰에 대한 데이터가 누락되었는지 여부를 나타내는 추가 변수 생성|누락이 있는 경우 누락의 중요성을 포착함.|기능 공간 확장|


실제 상황에서 누락된 메커니즘을 결정하기 어렵거나 누락된 각 변수에 대해 깊이 연구할 시간이 거의 없을 때 널리 사용되는 방법은 다음을 채택하는 것이다.

+ 평균/중앙값/모드 대치(분포에 따라 다름)
+ 배포 종료 귀속
+ NA를 나타내는 변수 추가

동시에 누락의 가치를 파악하고 완전한 데이터 세트를 얻을 수 있다.


## Outlier (이상치)

> 이상치(Outlier)란, 보통 관측된 데이터의 범위에서 많이 벗어난 아주 작은 값이나 큰 값을 말한다.

### 이상치가 중요한 이유

+ 알고리즘이 제대로 작동하지 않게 만듦
+ 표본의 대표성을 떨어뜨린다.


### 이상치 탐색 방법

|방법|정의|장점|단점|
|---|---|---|---|
| 임의의 경계로 감지	| 임의의 경계를 기반으로 이상값 식별	| 유연함|	이해가 필요함|
| 평균 및 표준 편차 방법	| 평균 및 표준편차 방법에 의한 이상치 검출	|가우시안 분포가 있는 변수에 적합	| 극단값 자체에 민감함 |
| IQR 방법 | 사분위수 범위 규칙에 의한 이상값 감지 | 분위수 및 IQR을 사용하므로 평균 및 표준 편차 방법보다 강력한 방법임 | 너무 위험할 수 있음 |
| MAD 방법 | Median 및 Median Absolute Deviation Method에 의한 이상값 탐지 | 평균 및 표준편차 방법보다 강력한 방법임  | 너무 위험할 수 있음 | 


### 이상치 처리 방법

|방법|정의|장점|단점|
|---|---|---|---|
| 평균/중앙값/모드 대치	| 이상값을 해당 변수의 평균/중앙값/가장 빈번한 값으로 대체	| 분포 보존	| 이상값이 있는 경우 해당 정보를 잃음.	|
| 이산화	| 연속 변수를 이산 변수로 변환	| 이상값의 영향 최소화	| 소화	이상값이 있는 경우 해당 정보를 잃음.	|
| 임의의 값으로 대치	| 임의의 값으로 이상값을 대치	| 유연함 | 값을 결정하기 힘듦	|
| 윈저화	| top-coding & bottom coding 	| 모델 과적합 방지	| 분포 왜곡	|
| 이상치 버리기	| 이상값인 모든 관측치를 삭제	| /	| 이상값이 있는 경우 해당 정보를 잃음.	|


## Rare Values (희귀 값)

> 일부 값을 가진 범주형 변수는 드물게 나타난다.


### Rare values가 중요한 이유

+ 범주형 변수의 희귀 값은 특히 트리 기반 방법 에서 과적합을 유발하는 경향이 있다.
+ 빈번하지 않은 레이블이 많으면 정보가 거의 없는 노이즈가 추가되어 과적합이 발생한다.
+ 드문 레이블이 훈련 세트에는 있지만 테스트 세트에는 없을 수 있으므로 훈련 세트에 과적합이 발생할 수 있다.
+ 희소한 레이블은 학습 세트가 아닌 테스트 세트에 나타날 수 있다. 따라서 모델은 이를 평가하는 방법을 알지 못한다.


### Rare values 처리 방법

+ 모드 대치 : 희귀 레이블을 가장 빈번한 레이블로 교체
+ 하나의 새로운 범주로 그룹화 : 희귀 레이블을 표시하는 관측치를 고유한 범주로 그룹화


## High Cardinality (높은 중복도)

>  범주형 변수 내의 레이블 수를 카디널리티라고 합니다. 변수 내의 레이블 수가 많은 것을 높은 카디널리티라고 한다.

### High Cardinality가 중요한 이유

+ 레이블이 너무 많은 변수는 특히 트리 기반 알고리즘 에서 레이블이 적은 변수보다 우세한 경향이 있다.
+ 변수 내의 레이블이 많으면 정보가 거의 없는 노이즈가 발생할 수 있으므로 기계 학습 모델이 과적합되기 쉽다.
+ 일부 레이블은 훈련 데이터 세트에만 있고 테스트 세트에는 없을 수 있으므로 알고리즘이 훈련 세트에 과적합될 수 있다.
+ 반대로 훈련 세트에 없는 새 레이블이 테스트 세트에 나타날 수 있으므로 알고리즘이 새 관찰에 대해 계산을 수행할 수 없게 된다.


### High Cardinality를 처리하는 방법

+ 비즈니스 이해를 바탕으로 레이블 그룹화
+ 드물게 발생하는 레이블을 하나의 범주로 그룹화
+ 의사 결정 트리로 레이블 그룹화