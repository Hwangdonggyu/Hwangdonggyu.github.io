---
title: 개굴캐글개굴 교차검증
date: 2023-11-02 14:04:00 +0900
categories: [AI,Tab_Study]
tags: [AI,Tab_Study]
---

![](https://velog.velcdn.com/images/acadias12/post/358c7f7f-00ec-4dd7-99a4-183615838474/image.png)

Tab study에서 같이 공부한 교차 검증에 대해 정리해보려 한다.


## 교차 검증

### 교차 검증이란?
>데이터를 여러 번 반복해서 나누고 여러 모델을 학습하여 성능을 평가하는 방법이다.

### 교차 검증을 사용하는 이유

+ 데이터셋에 대한 과적합을 방지할 수 있다.
+ 데이터셋 규모가 적을 시 과소적합을 방지할 수 있다.
+ 일반화된 모델 생성이 가능하다

### 검증 세트 나누기

![](https://velog.velcdn.com/images/acadias12/post/d531eeaf-88ac-40d4-be64-afdb65ec9fe0/image.png)

```python
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)

sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)
```

이전 스터디에서는 훈련 세트 80%, 테스트 세트 20%이었다. 하지만 검증 세트를 추가하면서 훈련세트 중에서 20퍼센트는 검증 세트로 분류시킨다.

### 교차 검증

<img src = "https://velog.velcdn.com/images/acadias12/post/e6b0e1b6-6dcc-4628-8747-53dd2cd452a0/image.png">

```python
from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)

print(scores)
```
교차 검증의 점수는 그림 처럼 1~5번 성능을 더한 것에 평균이다. sklearn에 cross_validate을 제공을 해줘서 이 모델을 통해 교차 검증을 진행할 수 있다.

#### Kfold 교차검증

```python
from sklearn.model_selection import StratifiedKFold

scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())


splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
```
KFold에서 cv를 통해 몇개의 폴드를 할 것인지 정할 수 있다. KFold에 매개변수로는 n_splits: 교차 검증을 위해 데이터를 몇 개의 폴드로 분할할지를 나타내는 정수 값이다. shuffle: 데이터를 분할하기 전에 섞을지 여부를 나타내는 부울 값이다. True로 설정하면 데이터를 무작위로 섞어서 각 폴드에 다양한 샘플이 들어가도록 한다.

### 그리드 서치 (Grid Search)

>그리드 서치(Grid Search)는 하이퍼파라미터를 일정한 간격으로 변경하며 최적의 파라미터를 찾아가는 기법이다.

```python
from sklearn.model_selection import GridSearchCV

params = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
            'max_depth': range(5, 20, 1),
            'min_samples_split': range(2, 100, 10)}

gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)

dt = gs.best_estimator_
```

#### params 매개변수 설명

+ min_impurity_decrease: 이 파라미터는 노드를 분할할 때 최소 불순도 감소(information gain)를 나타냄. 값이 높을수록 노드를 더 적게 분할하고, 값이 낮을수록 노드를 더 자주 분할하게 된다.

+ max_depth: 이 파라미터는 의사결정트리(Decision Tree)의 최대 깊이를 나타냄.

+ min_samples_split: 이 파라미터는 노드를 분할하기 위한 최소 샘플 수를 나타냄. 노드를 분할하기 위한 샘플 수가 이 값보다 작을 경우 더 이상 분할하지 않는다.

#### GridSearch 매개변수 설명

+ n_jobs: 병렬 처리를 사용하여 그리드 탐색을 가속화하는 데 사용되는 작업 수를 지정. -1로 설정하면 사용 가능한 모든 CPU 코어를 사용하게 됩니다.

GridSearch를 통해 최적의 파라미터를 찾을 수 있고 gs.best_estimator_를 통해 파라미터의 값 또한 볼 수 있다. 하지만 파라미터를 바꾸면서 반복하므로 시간이 오래 걸리는 단점이 있다.


## 느낀점
교차 검증을 배우면서 과적합 방지, 과소적합 방지, 모델의 일반화 등 여러가지 장점이 있다는 것을 확인했고 그리드 서치를 통해 최적의 파라미터를 찾을 수 있는 모델도 알게 되었다. 하지만 시간이 좀 걸릴 수 있으므로 잘 사용해야겠다고 느꼈다.