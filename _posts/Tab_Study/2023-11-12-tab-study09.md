---
title: 개굴캐글개굴 주성분 분석(PCA)
date: 2023-11-12 22:07:00 +0900
categories: [AI,Tab_Study]
tags: [AI,Tab_Study]
---

![](https://velog.velcdn.com/images/acadias12/post/358c7f7f-00ec-4dd7-99a4-183615838474/image.png)


Tab study에서 공부한 주성분 분석에 대해서 정리해보려 한다.

### 주성분 분석 (PCA)

>PCA는 대표적인 차원 축소 알고리즘이다. 차원 축소를 통해 데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도학습 모델의 성능을 향상시킬 수 있다.

![](https://velog.velcdn.com/images/acadias12/post/81a00cb4-9eff-4ff0-a7ef-0e22b808f61b/image.png)

PCA는 데이터에 있는 분산이 큰 방향을 찾는 것으로 이해할 수 있다. 위의 사진에서 분산이 큰 방향을 선택하여 선을 그려보면

![](https://velog.velcdn.com/images/acadias12/post/0fa002de-9a9d-4d97-a53c-227a6230ae85/image.png)

위의 사진처럼 길게 늘어진 대각선 방향이 분산이 가장 크다고 알 수 있다. 화살표의 위치는 큰 의미가 없다. 중요한 것은 **분산이 큰 방향**을 찾는 것이다.

![](https://velog.velcdn.com/images/acadias12/post/43a32feb-e086-4d6f-9864-9ab8e947b31b/image.png)

예를 들어, (2,1)의 벡터를 보자. 이 벡터를 **주성분**이라 부르는데, 원본 데이터에 있는 어떤 방향을 나타낸다.

+ 주성분은 원본 차원과 같고 주성분으로 바꾼 데이터는 차원이 줄어든다.


### PCA를 코드로 이해해보기

#### 데이터 셋 준비

```python
!wget https://bit.ly/fruits_300_data -O fruits_300.npy
import numpy as np
fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1, 100*100)
```

#### pca클래스 사용하기

```python
from sklearn.decomposition import PCA
pca = PCA(n_components=50)
pca.fit(fruits_2d)
```
PCA클래스를 만들 때 n_componentes 매개변수에 주성분의 개수를 지정해야 한다. 이 PCA는 비지도 학습이기 때문에 fit()메서드에 타겟값을 제공하지 않는다.

---

```python
print(fruits_2d.shape)
```
```
(300, 10000)
```

```python
fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)
```

```
(300, 50)
```
위의 코드 결과를 보면 10000개의 픽셀(특성)을 가진 300개의 이미지가 50개의 주성분을 찾은 PCA모델을 사용해 (300,50)크기의 배열로 변환한 것을 볼 수 있다. PCA를 통해 데이터의 차원을 줄이는 것을 확인해 볼 수 있다.

#### 원본 데이터로 복구하기

```python
fruits_inverse = pca.inverse_transform(fruits_pca)
print(fruits_inverse.shape)
```

```
(300, 10000)
```

데이터를 차원 축소를 하면 어쩔 수 없이 데이터 손실이 발생할 수 밖에 없다. 하지만 최대한 분산이 큰 방향으로 데이터를 투영했기 때문에 원본 데이터를 상당 부분 재구성할 수 있다. 
PCA 클래스에서 **inverse_transform()** 메서드를 통해 위의 코드처럼 원본 데이터로 복원을 할 수 있다.

#### Explained variance구하기

주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값을 **Explained variance**이라고 한다. PCA 클래스의 Explained_variance_ratio를 통해 분산 비율을 확인해보자.

```python
print(np.sum(pca.explained_variance_ratio_))
```

```
0.921517484011715
```

약 92%가 넘는 분산을 유지하고 있는 것을 확인할 수 있다.

```python
plt.plot(pca.explained_variance_ratio_)
plt.show()
```

![](https://velog.velcdn.com/images/acadias12/post/f07041af-092c-496e-bd05-98b014bc3863/image.png)

위의 그래프를 보면 처음 10개의 주성분이 대부분의 분산을 표현하고 있다는 것을 확인할 수 있다.

### 느낀점

PCA 즉 주성분 분석을 통해 일부 특성을 선택하여 데이터 크기를 줄이고 지도학습 모델의 성능을 향상시킬 수 있는 것에 신기함을 느꼈고, 불필요한 특성을 제거하는 것이 더 도움이 되는 것이구나라고 알게되었다.